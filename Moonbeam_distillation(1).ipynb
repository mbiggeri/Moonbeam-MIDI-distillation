{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMf1CRwYedvd"
      },
      "outputs": [],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOvV38kXeecu"
      },
      "outputs": [],
      "source": [
        "%pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJJ_OnYKekOK"
      },
      "outputs": [],
      "source": [
        "%pip install src/llama_recipes/transformers_minimal/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hpjn8v6ywVxc"
      },
      "outputs": [],
      "source": [
        "!pip uninstall llama_recipes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmnJK_a_j86a",
        "outputId": "c0bed4eb-de40-4f7e-d4b5-473730a5df61"
      },
      "outputs": [],
      "source": [
        "# Fondi l'adattatore e il modello base per creare correttamente il modello teacher\n",
        "!python \"C:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\recipes\\inference\\model_servers\\hf_text_generation_inference\\merge_lora_weights.py\" \\\n",
        "    --base_model \"C:\\Users\\Michael\\Desktop\\ModelliMusicGenerator\\MOONBEAM\\base_model\" \\\n",
        "    --peft_model \"C:\\Users\\Michael\\Desktop\\ModelliMusicGenerator\\MOONBEAM\\peft_model\" \\\n",
        "    --base_model_weights \"C:\\Users\\Michael\\Desktop\\ModelliMusicGenerator\\MOONBEAM\\base_model\\moonbeam_839M.pt\" \\\n",
        "    --output_dir \"C:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\models\\moonbeam_teacher_checkpoint\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsISsezjK4ro"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.sos_out_dict:{0: 0}, self.timeshift_dict:{0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10, 10: 11, 11: 12, 12: 13, 13: 14, 14: 15, 15: 16, 16: 17, 17: 18, 18: 19, 19: 20, 20: 21}, self.duration_dict:{0: 22, 1: 23, 2: 24, 3: 25, 4: 26, 5: 27, 6: 28, 7: 29, 8: 30, 9: 31, 10: 32, 11: 33, 12: 34, 13: 35, 14: 36, 15: 37, 16: 38, 17: 39, 18: 40, 19: 41, 20: 42, 21: 43, 22: 44, 23: 45, 24: 46, 25: 47, 26: 48, 27: 49, 28: 50, 29: 51, 30: 52, 31: 53, 32: 54, 33: 55, 34: 56, 35: 57, 36: 58, 37: 59, 38: 60, 39: 61, 40: 62, 41: 63, 42: 64, 43: 65, 44: 66, 45: 67, 46: 68, 47: 69, 48: 70, 49: 71, 50: 72, 51: 73, 52: 74, 53: 75, 54: 76, 55: 77, 56: 78, 57: 79, 58: 80, 59: 81, 60: 82, 61: 83, 62: 84, 63: 85, 64: 86, 65: 87, 66: 88, 67: 89, 68: 90, 69: 91, 70: 92, 71: 93, 72: 94, 73: 95, 74: 96, 75: 97, 76: 98, 77: 99, 78: 100, 79: 101, 80: 102, 81: 103, 82: 104, 83: 105, 84: 106, 85: 107, 86: 108, 87: 109, 88: 110, 89: 111, 90: 112, 91: 113, 92: 114, 93: 115, 94: 116, 95: 117, 96: 118, 97: 119, 98: 120, 99: 121, 100: 122, 101: 123, 102: 124, 103: 125, 104: 126, 105: 127, 106: 128, 107: 129, 108: 130, 109: 131, 110: 132, 111: 133, 112: 134, 113: 135, 114: 136, 115: 137, 116: 138, 117: 139, 118: 140, 119: 141, 120: 142, 121: 143, 122: 144, 123: 145, 124: 146, 125: 147, 126: 148, 127: 149, 128: 150, 129: 151, 130: 152, 131: 153, 132: 154, 133: 155, 134: 156, 135: 157, 136: 158, 137: 159, 138: 160, 139: 161, 140: 162, 141: 163, 142: 164, 143: 165, 144: 166, 145: 167, 146: 168, 147: 169, 148: 170, 149: 171, 150: 172, 151: 173, 152: 174, 153: 175, 154: 176, 155: 177, 156: 178, 157: 179, 158: 180, 159: 181, 160: 182, 161: 183, 162: 184, 163: 185, 164: 186, 165: 187, 166: 188, 167: 189, 168: 190, 169: 191, 170: 192, 171: 193, 172: 194, 173: 195, 174: 196, 175: 197, 176: 198, 177: 199, 178: 200, 179: 201, 180: 202, 181: 203, 182: 204, 183: 205, 184: 206, 185: 207, 186: 208, 187: 209, 188: 210, 189: 211, 190: 212, 191: 213, 192: 214, 193: 215, 194: 216, 195: 217, 196: 218, 197: 219, 198: 220, 199: 221, 200: 222, 201: 223, 202: 224, 203: 225, 204: 226, 205: 227, 206: 228, 207: 229, 208: 230, 209: 231, 210: 232, 211: 233, 212: 234, 213: 235, 214: 236, 215: 237, 216: 238, 217: 239, 218: 240, 219: 241, 220: 242, 221: 243, 222: 244, 223: 245, 224: 246, 225: 247, 226: 248, 227: 249, 228: 250, 229: 251, 230: 252, 231: 253, 232: 254, 233: 255, 234: 256, 235: 257, 236: 258, 237: 259, 238: 260, 239: 261, 240: 262, 241: 263, 242: 264, 243: 265, 244: 266, 245: 267, 246: 268, 247: 269, 248: 270, 249: 271, 250: 272, 251: 273, 252: 274, 253: 275, 254: 276, 255: 277, 256: 278, 257: 279, 258: 280, 259: 281, 260: 282, 261: 283, 262: 284, 263: 285, 264: 286, 265: 287, 266: 288, 267: 289, 268: 290, 269: 291, 270: 292, 271: 293, 272: 294, 273: 295, 274: 296, 275: 297, 276: 298, 277: 299, 278: 300, 279: 301, 280: 302, 281: 303, 282: 304, 283: 305, 284: 306, 285: 307, 286: 308, 287: 309, 288: 310, 289: 311, 290: 312, 291: 313, 292: 314, 293: 315, 294: 316, 295: 317, 296: 318, 297: 319, 298: 320, 299: 321, 300: 322, 301: 323, 302: 324, 303: 325, 304: 326, 305: 327, 306: 328, 307: 329, 308: 330, 309: 331, 310: 332, 311: 333, 312: 334, 313: 335, 314: 336, 315: 337, 316: 338, 317: 339, 318: 340, 319: 341, 320: 342, 321: 343, 322: 344, 323: 345, 324: 346, 325: 347, 326: 348, 327: 349, 328: 350, 329: 351, 330: 352, 331: 353, 332: 354, 333: 355, 334: 356, 335: 357, 336: 358, 337: 359, 338: 360, 339: 361, 340: 362, 341: 363, 342: 364, 343: 365, 344: 366, 345: 367, 346: 368, 347: 369, 348: 370, 349: 371, 350: 372, 351: 373, 352: 374, 353: 375, 354: 376, 355: 377, 356: 378, 357: 379, 358: 380, 359: 381, 360: 382, 361: 383, 362: 384, 363: 385, 364: 386, 365: 387, 366: 388, 367: 389, 368: 390, 369: 391, 370: 392, 371: 393, 372: 394, 373: 395, 374: 396, 375: 397, 376: 398, 377: 399, 378: 400, 379: 401, 380: 402, 381: 403, 382: 404, 383: 405, 384: 406, 385: 407, 386: 408, 387: 409, 388: 410, 389: 411, 390: 412, 391: 413, 392: 414, 393: 415, 394: 416, 395: 417, 396: 418, 397: 419, 398: 420, 399: 421, 400: 422, 401: 423, 402: 424, 403: 425, 404: 426, 405: 427, 406: 428, 407: 429, 408: 430, 409: 431, 410: 432, 411: 433, 412: 434, 413: 435, 414: 436, 415: 437, 416: 438, 417: 439, 418: 440, 419: 441, 420: 442, 421: 443, 422: 444, 423: 445, 424: 446, 425: 447, 426: 448, 427: 449, 428: 450, 429: 451, 430: 452, 431: 453, 432: 454, 433: 455, 434: 456, 435: 457, 436: 458, 437: 459, 438: 460, 439: 461, 440: 462, 441: 463, 442: 464, 443: 465, 444: 466, 445: 467, 446: 468, 447: 469, 448: 470, 449: 471, 450: 472, 451: 473, 452: 474, 453: 475, 454: 476, 455: 477, 456: 478, 457: 479, 458: 480, 459: 481, 460: 482, 461: 483, 462: 484, 463: 485, 464: 486, 465: 487, 466: 488, 467: 489, 468: 490, 469: 491, 470: 492, 471: 493, 472: 494, 473: 495, 474: 496, 475: 497, 476: 498, 477: 499, 478: 500, 479: 501, 480: 502, 481: 503, 482: 504, 483: 505, 484: 506, 485: 507, 486: 508, 487: 509, 488: 510, 489: 511, 490: 512, 491: 513, 492: 514, 493: 515, 494: 516, 495: 517, 496: 518, 497: 519, 498: 520, 499: 521, 500: 522, 501: 523, 502: 524, 503: 525, 504: 526, 505: 527, 506: 528, 507: 529, 508: 530, 509: 531, 510: 532, 511: 533, 512: 534, 513: 535, 514: 536, 515: 537, 516: 538, 517: 539, 518: 540, 519: 541, 520: 542, 521: 543, 522: 544, 523: 545, 524: 546, 525: 547, 526: 548, 527: 549, 528: 550, 529: 551, 530: 552, 531: 553, 532: 554, 533: 555, 534: 556, 535: 557, 536: 558, 537: 559, 538: 560, 539: 561, 540: 562, 541: 563, 542: 564, 543: 565, 544: 566, 545: 567, 546: 568, 547: 569, 548: 570, 549: 571, 550: 572, 551: 573, 552: 574, 553: 575, 554: 576, 555: 577, 556: 578, 557: 579, 558: 580, 559: 581, 560: 582, 561: 583, 562: 584, 563: 585, 564: 586, 565: 587, 566: 588, 567: 589, 568: 590, 569: 591, 570: 592, 571: 593, 572: 594, 573: 595, 574: 596, 575: 597, 576: 598, 577: 599, 578: 600, 579: 601, 580: 602, 581: 603, 582: 604, 583: 605, 584: 606, 585: 607, 586: 608, 587: 609, 588: 610, 589: 611, 590: 612, 591: 613, 592: 614, 593: 615, 594: 616, 595: 617, 596: 618, 597: 619, 598: 620, 599: 621, 600: 622, 601: 623, 602: 624, 603: 625, 604: 626, 605: 627, 606: 628, 607: 629, 608: 630, 609: 631, 610: 632, 611: 633, 612: 634, 613: 635, 614: 636, 615: 637, 616: 638, 617: 639, 618: 640, 619: 641, 620: 642, 621: 643, 622: 644, 623: 645, 624: 646, 625: 647, 626: 648, 627: 649, 628: 650, 629: 651, 630: 652, 631: 653, 632: 654, 633: 655, 634: 656, 635: 657, 636: 658, 637: 659, 638: 660, 639: 661, 640: 662, 641: 663, 642: 664, 643: 665, 644: 666, 645: 667, 646: 668, 647: 669, 648: 670, 649: 671, 650: 672, 651: 673, 652: 674, 653: 675, 654: 676, 655: 677, 656: 678, 657: 679, 658: 680, 659: 681, 660: 682, 661: 683, 662: 684, 663: 685, 664: 686, 665: 687, 666: 688, 667: 689, 668: 690, 669: 691, 670: 692, 671: 693, 672: 694, 673: 695, 674: 696, 675: 697, 676: 698, 677: 699, 678: 700, 679: 701, 680: 702, 681: 703, 682: 704, 683: 705, 684: 706, 685: 707, 686: 708, 687: 709, 688: 710, 689: 711, 690: 712, 691: 713, 692: 714, 693: 715, 694: 716, 695: 717, 696: 718, 697: 719, 698: 720, 699: 721, 700: 722, 701: 723, 702: 724, 703: 725, 704: 726, 705: 727, 706: 728, 707: 729, 708: 730, 709: 731, 710: 732, 711: 733, 712: 734, 713: 735, 714: 736, 715: 737, 716: 738, 717: 739, 718: 740, 719: 741, 720: 742, 721: 743, 722: 744, 723: 745, 724: 746, 725: 747, 726: 748, 727: 749, 728: 750, 729: 751, 730: 752, 731: 753, 732: 754, 733: 755, 734: 756, 735: 757, 736: 758, 737: 759, 738: 760, 739: 761, 740: 762, 741: 763, 742: 764, 743: 765, 744: 766, 745: 767, 746: 768, 747: 769, 748: 770, 749: 771, 750: 772, 751: 773, 752: 774, 753: 775, 754: 776, 755: 777, 756: 778, 757: 779, 758: 780, 759: 781, 760: 782, 761: 783, 762: 784, 763: 785, 764: 786, 765: 787, 766: 788, 767: 789, 768: 790, 769: 791, 770: 792, 771: 793, 772: 794, 773: 795, 774: 796, 775: 797, 776: 798, 777: 799, 778: 800, 779: 801, 780: 802, 781: 803, 782: 804, 783: 805, 784: 806, 785: 807, 786: 808, 787: 809, 788: 810, 789: 811, 790: 812, 791: 813, 792: 814, 793: 815, 794: 816, 795: 817, 796: 818, 797: 819, 798: 820, 799: 821, 800: 822, 801: 823, 802: 824, 803: 825, 804: 826, 805: 827, 806: 828, 807: 829, 808: 830, 809: 831, 810: 832, 811: 833, 812: 834, 813: 835, 814: 836, 815: 837, 816: 838, 817: 839, 818: 840, 819: 841, 820: 842, 821: 843, 822: 844, 823: 845, 824: 846, 825: 847, 826: 848, 827: 849, 828: 850, 829: 851, 830: 852, 831: 853, 832: 854, 833: 855, 834: 856, 835: 857, 836: 858, 837: 859, 838: 860, 839: 861, 840: 862, 841: 863, 842: 864, 843: 865, 844: 866, 845: 867, 846: 868, 847: 869, 848: 870, 849: 871, 850: 872, 851: 873, 852: 874, 853: 875, 854: 876, 855: 877, 856: 878, 857: 879, 858: 880, 859: 881, 860: 882, 861: 883, 862: 884, 863: 885, 864: 886, 865: 887, 866: 888, 867: 889, 868: 890, 869: 891, 870: 892, 871: 893, 872: 894, 873: 895, 874: 896, 875: 897, 876: 898, 877: 899, 878: 900, 879: 901, 880: 902, 881: 903, 882: 904, 883: 905, 884: 906, 885: 907, 886: 908, 887: 909, 888: 910, 889: 911, 890: 912, 891: 913, 892: 914, 893: 915, 894: 916, 895: 917, 896: 918, 897: 919, 898: 920, 899: 921, 900: 922, 901: 923, 902: 924, 903: 925, 904: 926, 905: 927, 906: 928, 907: 929, 908: 930, 909: 931, 910: 932, 911: 933, 912: 934, 913: 935, 914: 936, 915: 937, 916: 938, 917: 939, 918: 940, 919: 941, 920: 942, 921: 943, 922: 944, 923: 945, 924: 946, 925: 947, 926: 948, 927: 949, 928: 950, 929: 951, 930: 952, 931: 953, 932: 954, 933: 955, 934: 956, 935: 957, 936: 958, 937: 959, 938: 960, 939: 961, 940: 962, 941: 963, 942: 964, 943: 965, 944: 966, 945: 967, 946: 968, 947: 969, 948: 970, 949: 971, 950: 972, 951: 973, 952: 974, 953: 975, 954: 976, 955: 977, 956: 978, 957: 979, 958: 980, 959: 981, 960: 982, 961: 983, 962: 984, 963: 985, 964: 986, 965: 987, 966: 988, 967: 989, 968: 990, 969: 991, 970: 992, 971: 993, 972: 994, 973: 995, 974: 996, 975: 997, 976: 998, 977: 999, 978: 1000, 979: 1001, 980: 1002, 981: 1003, 982: 1004, 983: 1005, 984: 1006, 985: 1007, 986: 1008, 987: 1009, 988: 1010, 989: 1011, 990: 1012, 991: 1013, 992: 1014, 993: 1015, 994: 1016, 995: 1017, 996: 1018, 997: 1019, 998: 1020, 999: 1021, 1000: 1022},self.octave_dict:{0: 1023, 1: 1024, 2: 1025, 3: 1026, 4: 1027, 5: 1028, 6: 1029, 7: 1030, 8: 1031}, self.pitch_dict:{0: 1032, 1: 1033, 2: 1034, 3: 1035, 4: 1036, 5: 1037, 6: 1038, 7: 1039, 8: 1040, 9: 1041, 10: 1042, 11: 1043}, self.instrument_dict:{0: 1044, 1: 1045, 2: 1046, 3: 1047, 4: 1048, 5: 1049, 6: 1050, 7: 1051, 8: 1052, 9: 1053, 10: 1054, 11: 1055, 12: 1056, 13: 1057, 14: 1058, 15: 1059, 16: 1060, 17: 1061, 18: 1062, 19: 1063, 20: 1064, 21: 1065, 22: 1066, 23: 1067, 24: 1068, 25: 1069, 26: 1070, 27: 1071, 28: 1072, 29: 1073, 30: 1074, 31: 1075, 32: 1076, 33: 1077, 34: 1078, 35: 1079, 36: 1080, 37: 1081, 38: 1082, 39: 1083, 40: 1084, 41: 1085, 42: 1086, 43: 1087, 44: 1088, 45: 1089, 46: 1090, 47: 1091, 48: 1092, 49: 1093, 50: 1094, 51: 1095, 52: 1096, 53: 1097, 54: 1098, 55: 1099, 56: 1100, 57: 1101, 58: 1102, 59: 1103, 60: 1104, 61: 1105, 62: 1106, 63: 1107, 64: 1108, 65: 1109, 66: 1110, 67: 1111, 68: 1112, 69: 1113, 70: 1114, 71: 1115, 72: 1116, 73: 1117, 74: 1118, 75: 1119, 76: 1120, 77: 1121, 78: 1122, 79: 1123, 80: 1124, 81: 1125, 82: 1126, 83: 1127, 84: 1128, 85: 1129, 86: 1130, 87: 1131, 88: 1132, 89: 1133, 90: 1134, 91: 1135, 92: 1136, 93: 1137, 94: 1138, 95: 1139, 96: 1140, 97: 1141, 98: 1142, 99: 1143, 100: 1144, 101: 1145, 102: 1146, 103: 1147, 104: 1148, 105: 1149, 106: 1150, 107: 1151, 108: 1152, 109: 1153, 110: 1154, 111: 1155, 112: 1156, 113: 1157, 114: 1158, 115: 1159, 116: 1160, 117: 1161, 118: 1162, 119: 1163, 120: 1164, 121: 1165, 122: 1166, 123: 1167, 124: 1168, 125: 1169, 126: 1170, 127: 1171} self.velocity_dict:{0: 1172, 1: 1173, 2: 1174, 3: 1175, 4: 1176, 5: 1177, 6: 1178, 7: 1179, 8: 1180, 9: 1181, 10: 1182, 11: 1183, 12: 1184, 13: 1185, 14: 1186, 15: 1187, 16: 1188, 17: 1189, 18: 1190, 19: 1191, 20: 1192, 21: 1193, 22: 1194, 23: 1195, 24: 1196, 25: 1197, 26: 1198, 27: 1199, 28: 1200, 29: 1201, 30: 1202, 31: 1203, 32: 1204, 33: 1205, 34: 1206, 35: 1207, 36: 1208, 37: 1209, 38: 1210, 39: 1211, 40: 1212, 41: 1213, 42: 1214, 43: 1215, 44: 1216, 45: 1217, 46: 1218, 47: 1219, 48: 1220, 49: 1221, 50: 1222, 51: 1223, 52: 1224, 53: 1225, 54: 1226, 55: 1227, 56: 1228, 57: 1229, 58: 1230, 59: 1231, 60: 1232, 61: 1233, 62: 1234, 63: 1235, 64: 1236, 65: 1237, 66: 1238, 67: 1239, 68: 1240, 69: 1241, 70: 1242, 71: 1243, 72: 1244, 73: 1245, 74: 1246, 75: 1247, 76: 1248, 77: 1249, 78: 1250, 79: 1251, 80: 1252, 81: 1253, 82: 1254, 83: 1255, 84: 1256, 85: 1257, 86: 1258, 87: 1259, 88: 1260, 89: 1261, 90: 1262, 91: 1263, 92: 1264, 93: 1265, 94: 1266, 95: 1267, 96: 1268, 97: 1269, 98: 1270, 99: 1271, 100: 1272, 101: 1273, 102: 1274, 103: 1275, 104: 1276, 105: 1277, 106: 1278, 107: 1279, 108: 1280, 109: 1281, 110: 1282, 111: 1283, 112: 1284, 113: 1285, 114: 1286, 115: 1287, 116: 1288, 117: 1289, 118: 1290, 119: 1291, 120: 1292, 121: 1293, 122: 1294, 123: 1295, 124: 1296, 125: 1297, 126: 1298, 127: 1299, 128: 1300}\n",
            "Caricamento del modello Teacher: C:\\Users\\Michael\\Desktop\\ModelliMusicGenerator\\MOONBEAM\\base_model\n",
            "rope:inited\n",
            "rope:inited\n",
            "rope:inited\n",
            "rope:inited\n",
            "Modello Teacher caricato con successo.\n",
            "rope:inited\n",
            "Caricamento del modello Student da configurazione: C:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\src\\llama_recipes\\configs\\model_config_tiny.json\n",
            "rope:inited\n",
            "rope:inited\n",
            "Modello Student caricato con successo.\n",
            "Avvio della distillazione...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers and GPU quantization are unavailable.\n",
            "C:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\src\\llama_recipes\\model_checkpointing\\checkpoint_handler.py:17: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead\n",
            "  from torch.distributed._shard.checkpoint import (\n",
            "Some weights of the model checkpoint at C:\\Users\\Michael\\Desktop\\ModelliMusicGenerator\\MOONBEAM\\base_model were not used when initializing LlamaForCausalLM: ['epoch', 'model_state_dict', 'step']\n",
            "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at C:\\Users\\Michael\\Desktop\\ModelliMusicGenerator\\MOONBEAM\\base_model and are newly initialized: ['decoder.fc_out.bias', 'decoder.fc_out.weight', 'decoder.gru.bias_hh_l0', 'decoder.gru.bias_hh_l1', 'decoder.gru.bias_hh_l2', 'decoder.gru.bias_hh_l3', 'decoder.gru.bias_ih_l0', 'decoder.gru.bias_ih_l1', 'decoder.gru.bias_ih_l2', 'decoder.gru.bias_ih_l3', 'decoder.gru.weight_hh_l0', 'decoder.gru.weight_hh_l1', 'decoder.gru.weight_hh_l2', 'decoder.gru.weight_hh_l3', 'decoder.gru.weight_ih_l0', 'decoder.gru.weight_ih_l1', 'decoder.gru.weight_ih_l2', 'decoder.gru.weight_ih_l3', 'decoder_embedding.weight', 'lm_head.weight', 'model.dur_embedding.linear_fme.bias', 'model.dur_embedding.linear_fme.weight', 'model.dur_embedding.translation_bias', 'model.instrument_embedding.embedding.weight', 'model.layers.0.input_layernorm.weight', 'model.layers.0.mlp.down_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.0.post_attention_layernorm.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.input_layernorm.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.post_attention_layernorm.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.input_layernorm.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.post_attention_layernorm.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.input_layernorm.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.post_attention_layernorm.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.input_layernorm.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.post_attention_layernorm.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.input_layernorm.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.post_attention_layernorm.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.14.input_layernorm.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.post_attention_layernorm.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.2.input_layernorm.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.post_attention_layernorm.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.3.input_layernorm.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.post_attention_layernorm.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.4.input_layernorm.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.post_attention_layernorm.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.input_layernorm.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.post_attention_layernorm.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.input_layernorm.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.post_attention_layernorm.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.input_layernorm.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.post_attention_layernorm.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.input_layernorm.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.post_attention_layernorm.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.input_layernorm.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.post_attention_layernorm.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.norm.weight', 'model.octave_embedding.linear_fme.bias', 'model.octave_embedding.linear_fme.weight', 'model.octave_embedding.translation_bias', 'model.onset_embedding.linear_fme.bias', 'model.onset_embedding.linear_fme.weight', 'model.onset_embedding.translation_bias', 'model.pitch_embedding.linear_fme.bias', 'model.pitch_embedding.linear_fme.weight', 'model.pitch_embedding.translation_bias', 'model.supplementary_MLP.0.bias', 'model.supplementary_MLP.0.weight', 'model.supplementary_MLP.2.bias', 'model.supplementary_MLP.2.weight', 'model.supplementary_embedding.weight', 'model.velocity_embedding.linear_fme.bias', 'model.velocity_embedding.linear_fme.weight', 'model.velocity_embedding.translation_bias', 'summary_projection.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\n",
            "Epoch 1/5 [Training]:   0%|          | 0/24568 [00:00<?, ?it/s]The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers and GPU quantization are unavailable.\n",
            "C:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\src\\llama_recipes\\model_checkpointing\\checkpoint_handler.py:17: DeprecationWarning: `torch.distributed._shard.checkpoint` will be deprecated, use `torch.distributed.checkpoint` instead\n",
            "  from torch.distributed._shard.checkpoint import (\n",
            "\n",
            "Epoch 1/5 [Training]:   0%|          | 0/24568 [00:05<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\recipes\\distillation\\distillation.py\", line 150, in <module>\n",
            "    fire.Fire(main)\n",
            "  File \"c:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\.venv\\lib\\site-packages\\fire\\core.py\", line 135, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"c:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\.venv\\lib\\site-packages\\fire\\core.py\", line 468, in _Fire\n",
            "    component, remaining_args = _CallAndUpdateTrace(\n",
            "  File \"c:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\.venv\\lib\\site-packages\\fire\\core.py\", line 684, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"C:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\recipes\\distillation\\distillation.py\", line 134, in main\n",
            "    results = train_distillation(\n",
            "  File \"C:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\src\\llama_recipes\\utils\\train_utils.py\", line 120, in train_distillation\n",
            "    for step, batch in enumerate(pbar):\n",
            "  File \"c:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\.venv\\lib\\site-packages\\tqdm\\std.py\", line 1181, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"c:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 701, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"c:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1465, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"c:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1491, in _process_data\n",
            "    data.reraise()\n",
            "  File \"c:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\.venv\\lib\\site-packages\\torch\\_utils.py\", line 715, in reraise\n",
            "    raise exception\n",
            "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"c:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 351, in _worker_loop\n",
            "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
            "  File \"c:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"c:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"C:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\src\\llama_recipes\\datasets\\lakh_dataset.py\", line 30, in __getitem__\n",
            "    raw_tokens = np.load(os.path.join(self.data_dir, \"processed\",self.file_basenames[index]))\n",
            "  File \"c:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\.venv\\lib\\site-packages\\numpy\\lib\\npyio.py\", line 427, in load\n",
            "    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Michael\\\\Desktop\\\\MusicDatasets\\\\Datasets\\\\Moonbeam_Distillation\\\\processed_data\\\\processed\\\\processed\\\\3889ff677f6c42ec41f8598247557910.npy'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TRAINING DEL MODELLO DISTILLATO (TINY)\n",
        "!python \"C:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\recipes\\distillation\\distillation.py\" \\\n",
        "    --model_name \"C:\\Users\\Michael\\Desktop\\ModelliMusicGenerator\\MOONBEAM\\base_model\" \\\n",
        "    --model_config_file \"C:\\Users\\Michael\\Desktop\\Moonbeam-MIDI-Distillation\\src\\llama_recipes\\configs\\model_config_tiny.json\" \\\n",
        "    --csv_file \"C:\\Users\\Michael\\Desktop\\MusicDatasets\\Datasets\\Moonbeam_Distillation\\processed_data\\train_test_split.csv\" \\\n",
        "    --data_dir \"C:\\Users\\Michael\\Desktop\\MusicDatasets\\Datasets\\Moonbeam_Distillation\\processed_data\" \\\n",
        "    --output_dir \"C:\\Users\\Michael\\Desktop\\ModelliMusicGenerator\\MOONBEAM\\distilled\" \\\n",
        "    --alpha_distil 0.2 \\\n",
        "    --temperature 2.0 \\\n",
        "    --batch_size_training 4 \\\n",
        "    --num_epochs 5 \\\n",
        "    --lr 3e-5"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
